{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45dd3e9e-14a6-4a75-b2f4-ebf8bb3bc602",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cynth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\timm\\models\\layers\\__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "Florence2LanguageForConditionalGeneration has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoProcessor, AutoModelForCausalLM\n",
    "from peft import PeftModel\n",
    "\n",
    "# Constants\n",
    "MODEL_PATH = \"florence2-lora-20250209T125717Z-001_MODEL-3_15-EPOCHS/florence2-lora\"\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load Processor & Model\n",
    "processor = AutoProcessor.from_pretrained(MODEL_PATH, trust_remote_code=True)\n",
    "\n",
    "base_model_id = \"microsoft/Florence-2-base-ft\"\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model_id, trust_remote_code=True, revision=\"refs/pr/6\"\n",
    ").to(DEVICE)\n",
    "\n",
    "peft_model = PeftModel.from_pretrained(base_model, MODEL_PATH).to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553a938c",
   "metadata": {},
   "source": [
    "## This saves as a 410MB quantized pt model file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dfa7776",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.ao.quantization import quantize_dynamic\n",
    "quantized_model = quantize_dynamic(peft_model, {torch.nn.Linear}, dtype=torch.qint8)\n",
    "torch.save(quantized_model.state_dict(), \"florence2_lora_quantized.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a768a0ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForCausalLM(\n",
       "  (base_model): LoraModel(\n",
       "    (model): Florence2ForConditionalGeneration(\n",
       "      (vision_tower): DaViT(\n",
       "        (convs): ModuleList(\n",
       "          (0): ConvEmbed(\n",
       "            (proj): Conv2d(3, 128, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (1): ConvEmbed(\n",
       "            (proj): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (2): ConvEmbed(\n",
       "            (proj): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "            (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (3): ConvEmbed(\n",
       "            (proj): Conv2d(512, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "            (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (blocks): ModuleList(\n",
       "          (0): MySequential(\n",
       "            (0): MySequential(\n",
       "              (spatial_block): SpatialBlock(\n",
       "                (conv1): PreNorm(\n",
       "                  (fn): DepthWiseConv2d(\n",
       "                    (dw): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "                  )\n",
       "                )\n",
       "                (window_attn): PreNorm(\n",
       "                  (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "                  (fn): WindowAttention(\n",
       "                    (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
       "                    (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "                    (softmax): Softmax(dim=-1)\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "                (conv2): PreNorm(\n",
       "                  (fn): DepthWiseConv2d(\n",
       "                    (dw): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "                  )\n",
       "                )\n",
       "                (ffn): PreNorm(\n",
       "                  (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "                  (fn): Mlp(\n",
       "                    (net): Sequential(\n",
       "                      (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "                      (act): GELU(approximate='none')\n",
       "                      (fc2): lora.Linear(\n",
       "                        (base_layer): Linear(in_features=512, out_features=128, bias=True)\n",
       "                        (lora_dropout): ModuleDict(\n",
       "                          (default): Dropout(p=0.05, inplace=False)\n",
       "                        )\n",
       "                        (lora_A): ModuleDict(\n",
       "                          (default): Linear(in_features=512, out_features=8, bias=False)\n",
       "                        )\n",
       "                        (lora_B): ModuleDict(\n",
       "                          (default): Linear(in_features=8, out_features=128, bias=False)\n",
       "                        )\n",
       "                        (lora_embedding_A): ParameterDict()\n",
       "                        (lora_embedding_B): ParameterDict()\n",
       "                        (lora_magnitude_vector): ModuleDict()\n",
       "                      )\n",
       "                    )\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                )\n",
       "              )\n",
       "              (channel_block): ChannelBlock(\n",
       "                (conv1): PreNorm(\n",
       "                  (fn): DepthWiseConv2d(\n",
       "                    (dw): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "                  )\n",
       "                )\n",
       "                (channel_attn): PreNorm(\n",
       "                  (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "                  (fn): ChannelAttention(\n",
       "                    (qkv): Linear(in_features=128, out_features=384, bias=True)\n",
       "                    (proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "                  )\n",
       "                  (drop_path): DropPath(drop_prob=0.004)\n",
       "                )\n",
       "                (conv2): PreNorm(\n",
       "                  (fn): DepthWiseConv2d(\n",
       "                    (dw): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "                  )\n",
       "                )\n",
       "                (ffn): PreNorm(\n",
       "                  (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "                  (fn): Mlp(\n",
       "                    (net): Sequential(\n",
       "                      (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "                      (act): GELU(approximate='none')\n",
       "                      (fc2): lora.Linear(\n",
       "                        (base_layer): Linear(in_features=512, out_features=128, bias=True)\n",
       "                        (lora_dropout): ModuleDict(\n",
       "                          (default): Dropout(p=0.05, inplace=False)\n",
       "                        )\n",
       "                        (lora_A): ModuleDict(\n",
       "                          (default): Linear(in_features=512, out_features=8, bias=False)\n",
       "                        )\n",
       "                        (lora_B): ModuleDict(\n",
       "                          (default): Linear(in_features=8, out_features=128, bias=False)\n",
       "                        )\n",
       "                        (lora_embedding_A): ParameterDict()\n",
       "                        (lora_embedding_B): ParameterDict()\n",
       "                        (lora_magnitude_vector): ModuleDict()\n",
       "                      )\n",
       "                    )\n",
       "                  )\n",
       "                  (drop_path): DropPath(drop_prob=0.004)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (1): MySequential(\n",
       "            (0): MySequential(\n",
       "              (spatial_block): SpatialBlock(\n",
       "                (conv1): PreNorm(\n",
       "                  (fn): DepthWiseConv2d(\n",
       "                    (dw): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "                  )\n",
       "                )\n",
       "                (window_attn): PreNorm(\n",
       "                  (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "                  (fn): WindowAttention(\n",
       "                    (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
       "                    (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "                    (softmax): Softmax(dim=-1)\n",
       "                  )\n",
       "                  (drop_path): DropPath(drop_prob=0.009)\n",
       "                )\n",
       "                (conv2): PreNorm(\n",
       "                  (fn): DepthWiseConv2d(\n",
       "                    (dw): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "                  )\n",
       "                )\n",
       "                (ffn): PreNorm(\n",
       "                  (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "                  (fn): Mlp(\n",
       "                    (net): Sequential(\n",
       "                      (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "                      (act): GELU(approximate='none')\n",
       "                      (fc2): lora.Linear(\n",
       "                        (base_layer): Linear(in_features=1024, out_features=256, bias=True)\n",
       "                        (lora_dropout): ModuleDict(\n",
       "                          (default): Dropout(p=0.05, inplace=False)\n",
       "                        )\n",
       "                        (lora_A): ModuleDict(\n",
       "                          (default): Linear(in_features=1024, out_features=8, bias=False)\n",
       "                        )\n",
       "                        (lora_B): ModuleDict(\n",
       "                          (default): Linear(in_features=8, out_features=256, bias=False)\n",
       "                        )\n",
       "                        (lora_embedding_A): ParameterDict()\n",
       "                        (lora_embedding_B): ParameterDict()\n",
       "                        (lora_magnitude_vector): ModuleDict()\n",
       "                      )\n",
       "                    )\n",
       "                  )\n",
       "                  (drop_path): DropPath(drop_prob=0.009)\n",
       "                )\n",
       "              )\n",
       "              (channel_block): ChannelBlock(\n",
       "                (conv1): PreNorm(\n",
       "                  (fn): DepthWiseConv2d(\n",
       "                    (dw): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "                  )\n",
       "                )\n",
       "                (channel_attn): PreNorm(\n",
       "                  (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "                  (fn): ChannelAttention(\n",
       "                    (qkv): Linear(in_features=256, out_features=768, bias=True)\n",
       "                    (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "                  )\n",
       "                  (drop_path): DropPath(drop_prob=0.013)\n",
       "                )\n",
       "                (conv2): PreNorm(\n",
       "                  (fn): DepthWiseConv2d(\n",
       "                    (dw): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "                  )\n",
       "                )\n",
       "                (ffn): PreNorm(\n",
       "                  (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "                  (fn): Mlp(\n",
       "                    (net): Sequential(\n",
       "                      (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "                      (act): GELU(approximate='none')\n",
       "                      (fc2): lora.Linear(\n",
       "                        (base_layer): Linear(in_features=1024, out_features=256, bias=True)\n",
       "                        (lora_dropout): ModuleDict(\n",
       "                          (default): Dropout(p=0.05, inplace=False)\n",
       "                        )\n",
       "                        (lora_A): ModuleDict(\n",
       "                          (default): Linear(in_features=1024, out_features=8, bias=False)\n",
       "                        )\n",
       "                        (lora_B): ModuleDict(\n",
       "                          (default): Linear(in_features=8, out_features=256, bias=False)\n",
       "                        )\n",
       "                        (lora_embedding_A): ParameterDict()\n",
       "                        (lora_embedding_B): ParameterDict()\n",
       "                        (lora_magnitude_vector): ModuleDict()\n",
       "                      )\n",
       "                    )\n",
       "                  )\n",
       "                  (drop_path): DropPath(drop_prob=0.013)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (2): MySequential(\n",
       "            (0): MySequential(\n",
       "              (spatial_block): SpatialBlock(\n",
       "                (conv1): PreNorm(\n",
       "                  (fn): DepthWiseConv2d(\n",
       "                    (dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "                  )\n",
       "                )\n",
       "                (window_attn): PreNorm(\n",
       "                  (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (fn): WindowAttention(\n",
       "                    (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                    (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (softmax): Softmax(dim=-1)\n",
       "                  )\n",
       "                  (drop_path): DropPath(drop_prob=0.017)\n",
       "                )\n",
       "                (conv2): PreNorm(\n",
       "                  (fn): DepthWiseConv2d(\n",
       "                    (dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "                  )\n",
       "                )\n",
       "                (ffn): PreNorm(\n",
       "                  (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (fn): Mlp(\n",
       "                    (net): Sequential(\n",
       "                      (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                      (act): GELU(approximate='none')\n",
       "                      (fc2): lora.Linear(\n",
       "                        (base_layer): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                        (lora_dropout): ModuleDict(\n",
       "                          (default): Dropout(p=0.05, inplace=False)\n",
       "                        )\n",
       "                        (lora_A): ModuleDict(\n",
       "                          (default): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                        )\n",
       "                        (lora_B): ModuleDict(\n",
       "                          (default): Linear(in_features=8, out_features=512, bias=False)\n",
       "                        )\n",
       "                        (lora_embedding_A): ParameterDict()\n",
       "                        (lora_embedding_B): ParameterDict()\n",
       "                        (lora_magnitude_vector): ModuleDict()\n",
       "                      )\n",
       "                    )\n",
       "                  )\n",
       "                  (drop_path): DropPath(drop_prob=0.017)\n",
       "                )\n",
       "              )\n",
       "              (channel_block): ChannelBlock(\n",
       "                (conv1): PreNorm(\n",
       "                  (fn): DepthWiseConv2d(\n",
       "                    (dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "                  )\n",
       "                )\n",
       "                (channel_attn): PreNorm(\n",
       "                  (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (fn): ChannelAttention(\n",
       "                    (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                    (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  )\n",
       "                  (drop_path): DropPath(drop_prob=0.022)\n",
       "                )\n",
       "                (conv2): PreNorm(\n",
       "                  (fn): DepthWiseConv2d(\n",
       "                    (dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "                  )\n",
       "                )\n",
       "                (ffn): PreNorm(\n",
       "                  (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (fn): Mlp(\n",
       "                    (net): Sequential(\n",
       "                      (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                      (act): GELU(approximate='none')\n",
       "                      (fc2): lora.Linear(\n",
       "                        (base_layer): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                        (lora_dropout): ModuleDict(\n",
       "                          (default): Dropout(p=0.05, inplace=False)\n",
       "                        )\n",
       "                        (lora_A): ModuleDict(\n",
       "                          (default): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                        )\n",
       "                        (lora_B): ModuleDict(\n",
       "                          (default): Linear(in_features=8, out_features=512, bias=False)\n",
       "                        )\n",
       "                        (lora_embedding_A): ParameterDict()\n",
       "                        (lora_embedding_B): ParameterDict()\n",
       "                        (lora_magnitude_vector): ModuleDict()\n",
       "                      )\n",
       "                    )\n",
       "                  )\n",
       "                  (drop_path): DropPath(drop_prob=0.022)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): MySequential(\n",
       "              (spatial_block): SpatialBlock(\n",
       "                (conv1): PreNorm(\n",
       "                  (fn): DepthWiseConv2d(\n",
       "                    (dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "                  )\n",
       "                )\n",
       "                (window_attn): PreNorm(\n",
       "                  (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (fn): WindowAttention(\n",
       "                    (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                    (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (softmax): Softmax(dim=-1)\n",
       "                  )\n",
       "                  (drop_path): DropPath(drop_prob=0.026)\n",
       "                )\n",
       "                (conv2): PreNorm(\n",
       "                  (fn): DepthWiseConv2d(\n",
       "                    (dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "                  )\n",
       "                )\n",
       "                (ffn): PreNorm(\n",
       "                  (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (fn): Mlp(\n",
       "                    (net): Sequential(\n",
       "                      (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                      (act): GELU(approximate='none')\n",
       "                      (fc2): lora.Linear(\n",
       "                        (base_layer): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                        (lora_dropout): ModuleDict(\n",
       "                          (default): Dropout(p=0.05, inplace=False)\n",
       "                        )\n",
       "                        (lora_A): ModuleDict(\n",
       "                          (default): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                        )\n",
       "                        (lora_B): ModuleDict(\n",
       "                          (default): Linear(in_features=8, out_features=512, bias=False)\n",
       "                        )\n",
       "                        (lora_embedding_A): ParameterDict()\n",
       "                        (lora_embedding_B): ParameterDict()\n",
       "                        (lora_magnitude_vector): ModuleDict()\n",
       "                      )\n",
       "                    )\n",
       "                  )\n",
       "                  (drop_path): DropPath(drop_prob=0.026)\n",
       "                )\n",
       "              )\n",
       "              (channel_block): ChannelBlock(\n",
       "                (conv1): PreNorm(\n",
       "                  (fn): DepthWiseConv2d(\n",
       "                    (dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "                  )\n",
       "                )\n",
       "                (channel_attn): PreNorm(\n",
       "                  (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (fn): ChannelAttention(\n",
       "                    (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                    (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  )\n",
       "                  (drop_path): DropPath(drop_prob=0.030)\n",
       "                )\n",
       "                (conv2): PreNorm(\n",
       "                  (fn): DepthWiseConv2d(\n",
       "                    (dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "                  )\n",
       "                )\n",
       "                (ffn): PreNorm(\n",
       "                  (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (fn): Mlp(\n",
       "                    (net): Sequential(\n",
       "                      (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                      (act): GELU(approximate='none')\n",
       "                      (fc2): lora.Linear(\n",
       "                        (base_layer): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                        (lora_dropout): ModuleDict(\n",
       "                          (default): Dropout(p=0.05, inplace=False)\n",
       "                        )\n",
       "                        (lora_A): ModuleDict(\n",
       "                          (default): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                        )\n",
       "                        (lora_B): ModuleDict(\n",
       "                          (default): Linear(in_features=8, out_features=512, bias=False)\n",
       "                        )\n",
       "                        (lora_embedding_A): ParameterDict()\n",
       "                        (lora_embedding_B): ParameterDict()\n",
       "                        (lora_magnitude_vector): ModuleDict()\n",
       "                      )\n",
       "                    )\n",
       "                  )\n",
       "                  (drop_path): DropPath(drop_prob=0.030)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): MySequential(\n",
       "              (spatial_block): SpatialBlock(\n",
       "                (conv1): PreNorm(\n",
       "                  (fn): DepthWiseConv2d(\n",
       "                    (dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "                  )\n",
       "                )\n",
       "                (window_attn): PreNorm(\n",
       "                  (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (fn): WindowAttention(\n",
       "                    (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                    (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (softmax): Softmax(dim=-1)\n",
       "                  )\n",
       "                  (drop_path): DropPath(drop_prob=0.035)\n",
       "                )\n",
       "                (conv2): PreNorm(\n",
       "                  (fn): DepthWiseConv2d(\n",
       "                    (dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "                  )\n",
       "                )\n",
       "                (ffn): PreNorm(\n",
       "                  (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (fn): Mlp(\n",
       "                    (net): Sequential(\n",
       "                      (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                      (act): GELU(approximate='none')\n",
       "                      (fc2): lora.Linear(\n",
       "                        (base_layer): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                        (lora_dropout): ModuleDict(\n",
       "                          (default): Dropout(p=0.05, inplace=False)\n",
       "                        )\n",
       "                        (lora_A): ModuleDict(\n",
       "                          (default): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                        )\n",
       "                        (lora_B): ModuleDict(\n",
       "                          (default): Linear(in_features=8, out_features=512, bias=False)\n",
       "                        )\n",
       "                        (lora_embedding_A): ParameterDict()\n",
       "                        (lora_embedding_B): ParameterDict()\n",
       "                        (lora_magnitude_vector): ModuleDict()\n",
       "                      )\n",
       "                    )\n",
       "                  )\n",
       "                  (drop_path): DropPath(drop_prob=0.035)\n",
       "                )\n",
       "              )\n",
       "              (channel_block): ChannelBlock(\n",
       "                (conv1): PreNorm(\n",
       "                  (fn): DepthWiseConv2d(\n",
       "                    (dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "                  )\n",
       "                )\n",
       "                (channel_attn): PreNorm(\n",
       "                  (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (fn): ChannelAttention(\n",
       "                    (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                    (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  )\n",
       "                  (drop_path): DropPath(drop_prob=0.039)\n",
       "                )\n",
       "                (conv2): PreNorm(\n",
       "                  (fn): DepthWiseConv2d(\n",
       "                    (dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "                  )\n",
       "                )\n",
       "                (ffn): PreNorm(\n",
       "                  (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (fn): Mlp(\n",
       "                    (net): Sequential(\n",
       "                      (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                      (act): GELU(approximate='none')\n",
       "                      (fc2): lora.Linear(\n",
       "                        (base_layer): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                        (lora_dropout): ModuleDict(\n",
       "                          (default): Dropout(p=0.05, inplace=False)\n",
       "                        )\n",
       "                        (lora_A): ModuleDict(\n",
       "                          (default): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                        )\n",
       "                        (lora_B): ModuleDict(\n",
       "                          (default): Linear(in_features=8, out_features=512, bias=False)\n",
       "                        )\n",
       "                        (lora_embedding_A): ParameterDict()\n",
       "                        (lora_embedding_B): ParameterDict()\n",
       "                        (lora_magnitude_vector): ModuleDict()\n",
       "                      )\n",
       "                    )\n",
       "                  )\n",
       "                  (drop_path): DropPath(drop_prob=0.039)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): MySequential(\n",
       "              (spatial_block): SpatialBlock(\n",
       "                (conv1): PreNorm(\n",
       "                  (fn): DepthWiseConv2d(\n",
       "                    (dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "                  )\n",
       "                )\n",
       "                (window_attn): PreNorm(\n",
       "                  (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (fn): WindowAttention(\n",
       "                    (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                    (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (softmax): Softmax(dim=-1)\n",
       "                  )\n",
       "                  (drop_path): DropPath(drop_prob=0.043)\n",
       "                )\n",
       "                (conv2): PreNorm(\n",
       "                  (fn): DepthWiseConv2d(\n",
       "                    (dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "                  )\n",
       "                )\n",
       "                (ffn): PreNorm(\n",
       "                  (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (fn): Mlp(\n",
       "                    (net): Sequential(\n",
       "                      (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                      (act): GELU(approximate='none')\n",
       "                      (fc2): lora.Linear(\n",
       "                        (base_layer): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                        (lora_dropout): ModuleDict(\n",
       "                          (default): Dropout(p=0.05, inplace=False)\n",
       "                        )\n",
       "                        (lora_A): ModuleDict(\n",
       "                          (default): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                        )\n",
       "                        (lora_B): ModuleDict(\n",
       "                          (default): Linear(in_features=8, out_features=512, bias=False)\n",
       "                        )\n",
       "                        (lora_embedding_A): ParameterDict()\n",
       "                        (lora_embedding_B): ParameterDict()\n",
       "                        (lora_magnitude_vector): ModuleDict()\n",
       "                      )\n",
       "                    )\n",
       "                  )\n",
       "                  (drop_path): DropPath(drop_prob=0.043)\n",
       "                )\n",
       "              )\n",
       "              (channel_block): ChannelBlock(\n",
       "                (conv1): PreNorm(\n",
       "                  (fn): DepthWiseConv2d(\n",
       "                    (dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "                  )\n",
       "                )\n",
       "                (channel_attn): PreNorm(\n",
       "                  (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (fn): ChannelAttention(\n",
       "                    (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                    (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  )\n",
       "                  (drop_path): DropPath(drop_prob=0.048)\n",
       "                )\n",
       "                (conv2): PreNorm(\n",
       "                  (fn): DepthWiseConv2d(\n",
       "                    (dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "                  )\n",
       "                )\n",
       "                (ffn): PreNorm(\n",
       "                  (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (fn): Mlp(\n",
       "                    (net): Sequential(\n",
       "                      (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                      (act): GELU(approximate='none')\n",
       "                      (fc2): lora.Linear(\n",
       "                        (base_layer): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                        (lora_dropout): ModuleDict(\n",
       "                          (default): Dropout(p=0.05, inplace=False)\n",
       "                        )\n",
       "                        (lora_A): ModuleDict(\n",
       "                          (default): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                        )\n",
       "                        (lora_B): ModuleDict(\n",
       "                          (default): Linear(in_features=8, out_features=512, bias=False)\n",
       "                        )\n",
       "                        (lora_embedding_A): ParameterDict()\n",
       "                        (lora_embedding_B): ParameterDict()\n",
       "                        (lora_magnitude_vector): ModuleDict()\n",
       "                      )\n",
       "                    )\n",
       "                  )\n",
       "                  (drop_path): DropPath(drop_prob=0.048)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (4): MySequential(\n",
       "              (spatial_block): SpatialBlock(\n",
       "                (conv1): PreNorm(\n",
       "                  (fn): DepthWiseConv2d(\n",
       "                    (dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "                  )\n",
       "                )\n",
       "                (window_attn): PreNorm(\n",
       "                  (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (fn): WindowAttention(\n",
       "                    (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                    (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (softmax): Softmax(dim=-1)\n",
       "                  )\n",
       "                  (drop_path): DropPath(drop_prob=0.052)\n",
       "                )\n",
       "                (conv2): PreNorm(\n",
       "                  (fn): DepthWiseConv2d(\n",
       "                    (dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "                  )\n",
       "                )\n",
       "                (ffn): PreNorm(\n",
       "                  (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (fn): Mlp(\n",
       "                    (net): Sequential(\n",
       "                      (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                      (act): GELU(approximate='none')\n",
       "                      (fc2): lora.Linear(\n",
       "                        (base_layer): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                        (lora_dropout): ModuleDict(\n",
       "                          (default): Dropout(p=0.05, inplace=False)\n",
       "                        )\n",
       "                        (lora_A): ModuleDict(\n",
       "                          (default): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                        )\n",
       "                        (lora_B): ModuleDict(\n",
       "                          (default): Linear(in_features=8, out_features=512, bias=False)\n",
       "                        )\n",
       "                        (lora_embedding_A): ParameterDict()\n",
       "                        (lora_embedding_B): ParameterDict()\n",
       "                        (lora_magnitude_vector): ModuleDict()\n",
       "                      )\n",
       "                    )\n",
       "                  )\n",
       "                  (drop_path): DropPath(drop_prob=0.052)\n",
       "                )\n",
       "              )\n",
       "              (channel_block): ChannelBlock(\n",
       "                (conv1): PreNorm(\n",
       "                  (fn): DepthWiseConv2d(\n",
       "                    (dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "                  )\n",
       "                )\n",
       "                (channel_attn): PreNorm(\n",
       "                  (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (fn): ChannelAttention(\n",
       "                    (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                    (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  )\n",
       "                  (drop_path): DropPath(drop_prob=0.057)\n",
       "                )\n",
       "                (conv2): PreNorm(\n",
       "                  (fn): DepthWiseConv2d(\n",
       "                    (dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "                  )\n",
       "                )\n",
       "                (ffn): PreNorm(\n",
       "                  (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (fn): Mlp(\n",
       "                    (net): Sequential(\n",
       "                      (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                      (act): GELU(approximate='none')\n",
       "                      (fc2): lora.Linear(\n",
       "                        (base_layer): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                        (lora_dropout): ModuleDict(\n",
       "                          (default): Dropout(p=0.05, inplace=False)\n",
       "                        )\n",
       "                        (lora_A): ModuleDict(\n",
       "                          (default): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                        )\n",
       "                        (lora_B): ModuleDict(\n",
       "                          (default): Linear(in_features=8, out_features=512, bias=False)\n",
       "                        )\n",
       "                        (lora_embedding_A): ParameterDict()\n",
       "                        (lora_embedding_B): ParameterDict()\n",
       "                        (lora_magnitude_vector): ModuleDict()\n",
       "                      )\n",
       "                    )\n",
       "                  )\n",
       "                  (drop_path): DropPath(drop_prob=0.057)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (5): MySequential(\n",
       "              (spatial_block): SpatialBlock(\n",
       "                (conv1): PreNorm(\n",
       "                  (fn): DepthWiseConv2d(\n",
       "                    (dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "                  )\n",
       "                )\n",
       "                (window_attn): PreNorm(\n",
       "                  (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (fn): WindowAttention(\n",
       "                    (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                    (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (softmax): Softmax(dim=-1)\n",
       "                  )\n",
       "                  (drop_path): DropPath(drop_prob=0.061)\n",
       "                )\n",
       "                (conv2): PreNorm(\n",
       "                  (fn): DepthWiseConv2d(\n",
       "                    (dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "                  )\n",
       "                )\n",
       "                (ffn): PreNorm(\n",
       "                  (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (fn): Mlp(\n",
       "                    (net): Sequential(\n",
       "                      (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                      (act): GELU(approximate='none')\n",
       "                      (fc2): lora.Linear(\n",
       "                        (base_layer): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                        (lora_dropout): ModuleDict(\n",
       "                          (default): Dropout(p=0.05, inplace=False)\n",
       "                        )\n",
       "                        (lora_A): ModuleDict(\n",
       "                          (default): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                        )\n",
       "                        (lora_B): ModuleDict(\n",
       "                          (default): Linear(in_features=8, out_features=512, bias=False)\n",
       "                        )\n",
       "                        (lora_embedding_A): ParameterDict()\n",
       "                        (lora_embedding_B): ParameterDict()\n",
       "                        (lora_magnitude_vector): ModuleDict()\n",
       "                      )\n",
       "                    )\n",
       "                  )\n",
       "                  (drop_path): DropPath(drop_prob=0.061)\n",
       "                )\n",
       "              )\n",
       "              (channel_block): ChannelBlock(\n",
       "                (conv1): PreNorm(\n",
       "                  (fn): DepthWiseConv2d(\n",
       "                    (dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "                  )\n",
       "                )\n",
       "                (channel_attn): PreNorm(\n",
       "                  (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (fn): ChannelAttention(\n",
       "                    (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                    (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  )\n",
       "                  (drop_path): DropPath(drop_prob=0.065)\n",
       "                )\n",
       "                (conv2): PreNorm(\n",
       "                  (fn): DepthWiseConv2d(\n",
       "                    (dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "                  )\n",
       "                )\n",
       "                (ffn): PreNorm(\n",
       "                  (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (fn): Mlp(\n",
       "                    (net): Sequential(\n",
       "                      (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                      (act): GELU(approximate='none')\n",
       "                      (fc2): lora.Linear(\n",
       "                        (base_layer): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                        (lora_dropout): ModuleDict(\n",
       "                          (default): Dropout(p=0.05, inplace=False)\n",
       "                        )\n",
       "                        (lora_A): ModuleDict(\n",
       "                          (default): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                        )\n",
       "                        (lora_B): ModuleDict(\n",
       "                          (default): Linear(in_features=8, out_features=512, bias=False)\n",
       "                        )\n",
       "                        (lora_embedding_A): ParameterDict()\n",
       "                        (lora_embedding_B): ParameterDict()\n",
       "                        (lora_magnitude_vector): ModuleDict()\n",
       "                      )\n",
       "                    )\n",
       "                  )\n",
       "                  (drop_path): DropPath(drop_prob=0.065)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (6): MySequential(\n",
       "              (spatial_block): SpatialBlock(\n",
       "                (conv1): PreNorm(\n",
       "                  (fn): DepthWiseConv2d(\n",
       "                    (dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "                  )\n",
       "                )\n",
       "                (window_attn): PreNorm(\n",
       "                  (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (fn): WindowAttention(\n",
       "                    (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                    (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (softmax): Softmax(dim=-1)\n",
       "                  )\n",
       "                  (drop_path): DropPath(drop_prob=0.070)\n",
       "                )\n",
       "                (conv2): PreNorm(\n",
       "                  (fn): DepthWiseConv2d(\n",
       "                    (dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "                  )\n",
       "                )\n",
       "                (ffn): PreNorm(\n",
       "                  (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (fn): Mlp(\n",
       "                    (net): Sequential(\n",
       "                      (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                      (act): GELU(approximate='none')\n",
       "                      (fc2): lora.Linear(\n",
       "                        (base_layer): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                        (lora_dropout): ModuleDict(\n",
       "                          (default): Dropout(p=0.05, inplace=False)\n",
       "                        )\n",
       "                        (lora_A): ModuleDict(\n",
       "                          (default): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                        )\n",
       "                        (lora_B): ModuleDict(\n",
       "                          (default): Linear(in_features=8, out_features=512, bias=False)\n",
       "                        )\n",
       "                        (lora_embedding_A): ParameterDict()\n",
       "                        (lora_embedding_B): ParameterDict()\n",
       "                        (lora_magnitude_vector): ModuleDict()\n",
       "                      )\n",
       "                    )\n",
       "                  )\n",
       "                  (drop_path): DropPath(drop_prob=0.070)\n",
       "                )\n",
       "              )\n",
       "              (channel_block): ChannelBlock(\n",
       "                (conv1): PreNorm(\n",
       "                  (fn): DepthWiseConv2d(\n",
       "                    (dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "                  )\n",
       "                )\n",
       "                (channel_attn): PreNorm(\n",
       "                  (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (fn): ChannelAttention(\n",
       "                    (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                    (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  )\n",
       "                  (drop_path): DropPath(drop_prob=0.074)\n",
       "                )\n",
       "                (conv2): PreNorm(\n",
       "                  (fn): DepthWiseConv2d(\n",
       "                    (dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "                  )\n",
       "                )\n",
       "                (ffn): PreNorm(\n",
       "                  (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (fn): Mlp(\n",
       "                    (net): Sequential(\n",
       "                      (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                      (act): GELU(approximate='none')\n",
       "                      (fc2): lora.Linear(\n",
       "                        (base_layer): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                        (lora_dropout): ModuleDict(\n",
       "                          (default): Dropout(p=0.05, inplace=False)\n",
       "                        )\n",
       "                        (lora_A): ModuleDict(\n",
       "                          (default): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                        )\n",
       "                        (lora_B): ModuleDict(\n",
       "                          (default): Linear(in_features=8, out_features=512, bias=False)\n",
       "                        )\n",
       "                        (lora_embedding_A): ParameterDict()\n",
       "                        (lora_embedding_B): ParameterDict()\n",
       "                        (lora_magnitude_vector): ModuleDict()\n",
       "                      )\n",
       "                    )\n",
       "                  )\n",
       "                  (drop_path): DropPath(drop_prob=0.074)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (7): MySequential(\n",
       "              (spatial_block): SpatialBlock(\n",
       "                (conv1): PreNorm(\n",
       "                  (fn): DepthWiseConv2d(\n",
       "                    (dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "                  )\n",
       "                )\n",
       "                (window_attn): PreNorm(\n",
       "                  (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (fn): WindowAttention(\n",
       "                    (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                    (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (softmax): Softmax(dim=-1)\n",
       "                  )\n",
       "                  (drop_path): DropPath(drop_prob=0.078)\n",
       "                )\n",
       "                (conv2): PreNorm(\n",
       "                  (fn): DepthWiseConv2d(\n",
       "                    (dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "                  )\n",
       "                )\n",
       "                (ffn): PreNorm(\n",
       "                  (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (fn): Mlp(\n",
       "                    (net): Sequential(\n",
       "                      (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                      (act): GELU(approximate='none')\n",
       "                      (fc2): lora.Linear(\n",
       "                        (base_layer): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                        (lora_dropout): ModuleDict(\n",
       "                          (default): Dropout(p=0.05, inplace=False)\n",
       "                        )\n",
       "                        (lora_A): ModuleDict(\n",
       "                          (default): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                        )\n",
       "                        (lora_B): ModuleDict(\n",
       "                          (default): Linear(in_features=8, out_features=512, bias=False)\n",
       "                        )\n",
       "                        (lora_embedding_A): ParameterDict()\n",
       "                        (lora_embedding_B): ParameterDict()\n",
       "                        (lora_magnitude_vector): ModuleDict()\n",
       "                      )\n",
       "                    )\n",
       "                  )\n",
       "                  (drop_path): DropPath(drop_prob=0.078)\n",
       "                )\n",
       "              )\n",
       "              (channel_block): ChannelBlock(\n",
       "                (conv1): PreNorm(\n",
       "                  (fn): DepthWiseConv2d(\n",
       "                    (dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "                  )\n",
       "                )\n",
       "                (channel_attn): PreNorm(\n",
       "                  (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (fn): ChannelAttention(\n",
       "                    (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                    (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  )\n",
       "                  (drop_path): DropPath(drop_prob=0.083)\n",
       "                )\n",
       "                (conv2): PreNorm(\n",
       "                  (fn): DepthWiseConv2d(\n",
       "                    (dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "                  )\n",
       "                )\n",
       "                (ffn): PreNorm(\n",
       "                  (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (fn): Mlp(\n",
       "                    (net): Sequential(\n",
       "                      (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                      (act): GELU(approximate='none')\n",
       "                      (fc2): lora.Linear(\n",
       "                        (base_layer): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                        (lora_dropout): ModuleDict(\n",
       "                          (default): Dropout(p=0.05, inplace=False)\n",
       "                        )\n",
       "                        (lora_A): ModuleDict(\n",
       "                          (default): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                        )\n",
       "                        (lora_B): ModuleDict(\n",
       "                          (default): Linear(in_features=8, out_features=512, bias=False)\n",
       "                        )\n",
       "                        (lora_embedding_A): ParameterDict()\n",
       "                        (lora_embedding_B): ParameterDict()\n",
       "                        (lora_magnitude_vector): ModuleDict()\n",
       "                      )\n",
       "                    )\n",
       "                  )\n",
       "                  (drop_path): DropPath(drop_prob=0.083)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (8): MySequential(\n",
       "              (spatial_block): SpatialBlock(\n",
       "                (conv1): PreNorm(\n",
       "                  (fn): DepthWiseConv2d(\n",
       "                    (dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "                  )\n",
       "                )\n",
       "                (window_attn): PreNorm(\n",
       "                  (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (fn): WindowAttention(\n",
       "                    (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                    (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                    (softmax): Softmax(dim=-1)\n",
       "                  )\n",
       "                  (drop_path): DropPath(drop_prob=0.087)\n",
       "                )\n",
       "                (conv2): PreNorm(\n",
       "                  (fn): DepthWiseConv2d(\n",
       "                    (dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "                  )\n",
       "                )\n",
       "                (ffn): PreNorm(\n",
       "                  (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (fn): Mlp(\n",
       "                    (net): Sequential(\n",
       "                      (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                      (act): GELU(approximate='none')\n",
       "                      (fc2): lora.Linear(\n",
       "                        (base_layer): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                        (lora_dropout): ModuleDict(\n",
       "                          (default): Dropout(p=0.05, inplace=False)\n",
       "                        )\n",
       "                        (lora_A): ModuleDict(\n",
       "                          (default): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                        )\n",
       "                        (lora_B): ModuleDict(\n",
       "                          (default): Linear(in_features=8, out_features=512, bias=False)\n",
       "                        )\n",
       "                        (lora_embedding_A): ParameterDict()\n",
       "                        (lora_embedding_B): ParameterDict()\n",
       "                        (lora_magnitude_vector): ModuleDict()\n",
       "                      )\n",
       "                    )\n",
       "                  )\n",
       "                  (drop_path): DropPath(drop_prob=0.087)\n",
       "                )\n",
       "              )\n",
       "              (channel_block): ChannelBlock(\n",
       "                (conv1): PreNorm(\n",
       "                  (fn): DepthWiseConv2d(\n",
       "                    (dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "                  )\n",
       "                )\n",
       "                (channel_attn): PreNorm(\n",
       "                  (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (fn): ChannelAttention(\n",
       "                    (qkv): Linear(in_features=512, out_features=1536, bias=True)\n",
       "                    (proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "                  )\n",
       "                  (drop_path): DropPath(drop_prob=0.091)\n",
       "                )\n",
       "                (conv2): PreNorm(\n",
       "                  (fn): DepthWiseConv2d(\n",
       "                    (dw): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512)\n",
       "                  )\n",
       "                )\n",
       "                (ffn): PreNorm(\n",
       "                  (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "                  (fn): Mlp(\n",
       "                    (net): Sequential(\n",
       "                      (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                      (act): GELU(approximate='none')\n",
       "                      (fc2): lora.Linear(\n",
       "                        (base_layer): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                        (lora_dropout): ModuleDict(\n",
       "                          (default): Dropout(p=0.05, inplace=False)\n",
       "                        )\n",
       "                        (lora_A): ModuleDict(\n",
       "                          (default): Linear(in_features=2048, out_features=8, bias=False)\n",
       "                        )\n",
       "                        (lora_B): ModuleDict(\n",
       "                          (default): Linear(in_features=8, out_features=512, bias=False)\n",
       "                        )\n",
       "                        (lora_embedding_A): ParameterDict()\n",
       "                        (lora_embedding_B): ParameterDict()\n",
       "                        (lora_magnitude_vector): ModuleDict()\n",
       "                      )\n",
       "                    )\n",
       "                  )\n",
       "                  (drop_path): DropPath(drop_prob=0.091)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (3): MySequential(\n",
       "            (0): MySequential(\n",
       "              (spatial_block): SpatialBlock(\n",
       "                (conv1): PreNorm(\n",
       "                  (fn): DepthWiseConv2d(\n",
       "                    (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "                  )\n",
       "                )\n",
       "                (window_attn): PreNorm(\n",
       "                  (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                  (fn): WindowAttention(\n",
       "                    (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "                    (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                    (softmax): Softmax(dim=-1)\n",
       "                  )\n",
       "                  (drop_path): DropPath(drop_prob=0.096)\n",
       "                )\n",
       "                (conv2): PreNorm(\n",
       "                  (fn): DepthWiseConv2d(\n",
       "                    (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "                  )\n",
       "                )\n",
       "                (ffn): PreNorm(\n",
       "                  (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                  (fn): Mlp(\n",
       "                    (net): Sequential(\n",
       "                      (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                      (act): GELU(approximate='none')\n",
       "                      (fc2): lora.Linear(\n",
       "                        (base_layer): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                        (lora_dropout): ModuleDict(\n",
       "                          (default): Dropout(p=0.05, inplace=False)\n",
       "                        )\n",
       "                        (lora_A): ModuleDict(\n",
       "                          (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                        )\n",
       "                        (lora_B): ModuleDict(\n",
       "                          (default): Linear(in_features=8, out_features=1024, bias=False)\n",
       "                        )\n",
       "                        (lora_embedding_A): ParameterDict()\n",
       "                        (lora_embedding_B): ParameterDict()\n",
       "                        (lora_magnitude_vector): ModuleDict()\n",
       "                      )\n",
       "                    )\n",
       "                  )\n",
       "                  (drop_path): DropPath(drop_prob=0.096)\n",
       "                )\n",
       "              )\n",
       "              (channel_block): ChannelBlock(\n",
       "                (conv1): PreNorm(\n",
       "                  (fn): DepthWiseConv2d(\n",
       "                    (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "                  )\n",
       "                )\n",
       "                (channel_attn): PreNorm(\n",
       "                  (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                  (fn): ChannelAttention(\n",
       "                    (qkv): Linear(in_features=1024, out_features=3072, bias=True)\n",
       "                    (proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "                  )\n",
       "                  (drop_path): DropPath(drop_prob=0.100)\n",
       "                )\n",
       "                (conv2): PreNorm(\n",
       "                  (fn): DepthWiseConv2d(\n",
       "                    (dw): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "                  )\n",
       "                )\n",
       "                (ffn): PreNorm(\n",
       "                  (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "                  (fn): Mlp(\n",
       "                    (net): Sequential(\n",
       "                      (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                      (act): GELU(approximate='none')\n",
       "                      (fc2): lora.Linear(\n",
       "                        (base_layer): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                        (lora_dropout): ModuleDict(\n",
       "                          (default): Dropout(p=0.05, inplace=False)\n",
       "                        )\n",
       "                        (lora_A): ModuleDict(\n",
       "                          (default): Linear(in_features=4096, out_features=8, bias=False)\n",
       "                        )\n",
       "                        (lora_B): ModuleDict(\n",
       "                          (default): Linear(in_features=8, out_features=1024, bias=False)\n",
       "                        )\n",
       "                        (lora_embedding_A): ParameterDict()\n",
       "                        (lora_embedding_B): ParameterDict()\n",
       "                        (lora_magnitude_vector): ModuleDict()\n",
       "                      )\n",
       "                    )\n",
       "                  )\n",
       "                  (drop_path): DropPath(drop_prob=0.100)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (avgpool): AdaptiveAvgPool1d(output_size=1)\n",
       "      )\n",
       "      (image_proj_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (image_pos_embed): LearnedAbsolutePositionEmbedding2D(\n",
       "        (row_embeddings): Embedding(50, 512)\n",
       "        (column_embeddings): Embedding(50, 512)\n",
       "      )\n",
       "      (visual_temporal_embed): PositionalEmbeddingCosine1D()\n",
       "      (language_model): Florence2LanguageForConditionalGeneration(\n",
       "        (model): Florence2LanguageModel(\n",
       "          (shared): Embedding(51289, 768, padding_idx=1)\n",
       "          (encoder): Florence2Encoder(\n",
       "            (embed_tokens): Florence2ScaledWordEmbedding(51289, 768, padding_idx=1)\n",
       "            (embed_positions): Florence2LearnedPositionalEmbedding(1026, 768)\n",
       "            (layers): ModuleList(\n",
       "              (0-5): 6 x Florence2EncoderLayer(\n",
       "                (self_attn): Florence2SdpaAttention(\n",
       "                  (k_proj): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.05, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (v_proj): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.05, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (q_proj): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.05, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                )\n",
       "                (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (activation_fn): GELUActivation()\n",
       "                (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (fc2): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.05, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=3072, out_features=8, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "          (decoder): Florence2Decoder(\n",
       "            (embed_tokens): Florence2ScaledWordEmbedding(51289, 768, padding_idx=1)\n",
       "            (embed_positions): Florence2LearnedPositionalEmbedding(1026, 768)\n",
       "            (layers): ModuleList(\n",
       "              (0-5): 6 x Florence2DecoderLayer(\n",
       "                (self_attn): Florence2SdpaAttention(\n",
       "                  (k_proj): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.05, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (v_proj): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.05, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (q_proj): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.05, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                )\n",
       "                (activation_fn): GELUActivation()\n",
       "                (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (encoder_attn): Florence2SdpaAttention(\n",
       "                  (k_proj): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.05, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (v_proj): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.05, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (q_proj): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.05, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "                )\n",
       "                (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (fc2): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.05, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=3072, out_features=8, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=8, out_features=768, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                  (lora_magnitude_vector): ModuleDict()\n",
       "                )\n",
       "                (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "            )\n",
       "            (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "        (lm_head): lora.Linear(\n",
       "          (base_layer): Linear(in_features=768, out_features=51289, bias=False)\n",
       "          (lora_dropout): ModuleDict(\n",
       "            (default): Dropout(p=0.05, inplace=False)\n",
       "          )\n",
       "          (lora_A): ModuleDict(\n",
       "            (default): Linear(in_features=768, out_features=8, bias=False)\n",
       "          )\n",
       "          (lora_B): ModuleDict(\n",
       "            (default): Linear(in_features=8, out_features=51289, bias=False)\n",
       "          )\n",
       "          (lora_embedding_A): ParameterDict()\n",
       "          (lora_embedding_B): ParameterDict()\n",
       "          (lora_magnitude_vector): ModuleDict()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_model.eval()\n",
    "peft_model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfadb64c",
   "metadata": {},
   "source": [
    "## This prunes the model, but still same size 410MB, not great"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92767e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cynth\\AppData\\Local\\Temp\\ipykernel_15160\\2409068483.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model = torch.load(checkpoint_path, map_location=\"cpu\")\n",
      "c:\\Users\\cynth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_utils.py:392: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  device=storage.device,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruned model saved as florence2_lora_quantized_pruned.pt\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.utils.prune as prune\n",
    "\n",
    "checkpoint_path = \"florence2_lora_quantized.pt\"\n",
    "\n",
    "# Load model\n",
    "model = torch.load(checkpoint_path, map_location=\"cpu\")\n",
    "\n",
    "# Apply pruning (removing 50% of weights in linear layers)\n",
    "for name, module in model.items():\n",
    "    if isinstance(module, torch.nn.Linear):  # Apply pruning to linear layers\n",
    "        prune.l1_unstructured(module, name=\"weight\", amount=0.5)\n",
    "\n",
    "# Save pruned model\n",
    "pruned_checkpoint_path = \"florence2_lora_quantized_pruned.pt\"\n",
    "torch.save(model, pruned_checkpoint_path)\n",
    "print(f\"Pruned model saved as {pruned_checkpoint_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30aa2fb6",
   "metadata": {},
   "source": [
    "##  INT8 or FP16 Quantization: This reduces size to 344MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d6e216b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cynth\\AppData\\Local\\Temp\\ipykernel_15160\\1018565509.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantized checkpoint saved as florence2_lora_quantized_pruned_int8.pt\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "checkpoint_path = \"florence2_lora_quantized_pruned.pt\"\n",
    "quantized_checkpoint_path = \"florence2_lora_quantized_pruned_int8.pt\"  # Change to _fp16.pt if using float16\n",
    "\n",
    "# Load checkpoint\n",
    "checkpoint = torch.load(checkpoint_path, map_location=\"cpu\")\n",
    "\n",
    "# Convert all tensor values in the state_dict\n",
    "for key in checkpoint:\n",
    "    if isinstance(checkpoint[key], torch.Tensor):  # Only convert tensors\n",
    "        checkpoint[key] = checkpoint[key].to(torch.int8)  # Change to .to(torch.float16) for FP16\n",
    "\n",
    "# Save quantized checkpoint\n",
    "torch.save(checkpoint, quantized_checkpoint_path)\n",
    "print(f\"Quantized checkpoint saved as {quantized_checkpoint_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee253bb9",
   "metadata": {},
   "source": [
    "## This saves as a 338MB onnx model file using VIT Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15ae5457",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cynth\\AppData\\Local\\Temp\\ipykernel_15160\\240920803.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=torch.device('cpu'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrained Florence v2 LoRA quantized weights loaded successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cynth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\__init__.py:2040: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert condition, message\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model exported successfully to vit_base_patch16_224_florence2.onnx\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import timm\n",
    "import onnx\n",
    "\n",
    "# Load the ViT model\n",
    "model_name = \"vit_base_patch16_224\"\n",
    "model = timm.create_model(model_name, pretrained=False)  # No need to load default weights\n",
    "model.eval()  # Set to evaluation mode\n",
    "\n",
    "# Load pretrained Florence v2 LoRA quantized weights\n",
    "checkpoint_path = \"florence2_lora_quantized_pruned_int8.pt\"\n",
    "checkpoint = torch.load(checkpoint_path, map_location=torch.device('cpu'))\n",
    "\n",
    "# Load weights into the model\n",
    "model.load_state_dict(checkpoint, strict=False)  # Use strict=False in case of mismatched keys\n",
    "\n",
    "print(\"Pretrained Florence v2 LoRA quantized weights loaded successfully!\")\n",
    "\n",
    "# Dummy input (batch_size=1, 3 color channels, 224x224 image size)\n",
    "dummy_input = torch.randn(1, 3, 224, 224)\n",
    "\n",
    "# Export to ONNX\n",
    "onnx_path = \"vit_base_patch16_224_florence2.onnx\"\n",
    "torch.onnx.export(\n",
    "    model, \n",
    "    dummy_input, \n",
    "    onnx_path, \n",
    "    input_names=[\"input\"], \n",
    "    output_names=[\"output\"], \n",
    "    dynamic_axes={\"input\": {0: \"batch_size\"}, \"output\": {0: \"batch_size\"}}, \n",
    "    opset_version=14  # Use a compatible ONNX opset version\n",
    ")\n",
    "\n",
    "print(f\"Model exported successfully to {onnx_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d0f34c",
   "metadata": {},
   "source": [
    "## This saves as a 86MB onnx model file using VIT Small Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c5277e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cynth\\AppData\\Local\\Temp\\ipykernel_15160\\3363559158.py:12: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=torch.device(\"cpu\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrained Florence v2 LoRA quantized weights loaded successfully!\n",
      "Model exported successfully to vit_small_patch16_224_florence2.onnx\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import timm\n",
    "import onnx\n",
    "\n",
    "# Use a smaller ViT model\n",
    "model_name = \"vit_small_patch16_224\"  # Use \"vit_tiny_patch16_224\" for an even smaller model\n",
    "model = timm.create_model(model_name, pretrained=False)  \n",
    "model.eval()  # Set to evaluation mode\n",
    "\n",
    "# Load pretrained Florence v2 LoRA quantized weights\n",
    "checkpoint_path = \"florence2_lora_quantized_pruned_int8.pt\"\n",
    "checkpoint = torch.load(checkpoint_path, map_location=torch.device(\"cpu\"))\n",
    "\n",
    "# Load weights into the model\n",
    "model.load_state_dict(checkpoint, strict=False)  # Allow mismatched keys\n",
    "\n",
    "print(\"Pretrained Florence v2 LoRA quantized weights loaded successfully!\")\n",
    "\n",
    "# Dummy input for ONNX export (batch_size=1, 3 color channels, 224x224 image size)\n",
    "dummy_input = torch.randn(1, 3, 224, 224)\n",
    "\n",
    "# Export to ONNX\n",
    "onnx_path = \"vit_small_patch16_224_florence2.onnx\"  # Change to vit_tiny_patch16_224_florence2.onnx for a smaller model\n",
    "torch.onnx.export(\n",
    "    model, \n",
    "    dummy_input, \n",
    "    onnx_path, \n",
    "    input_names=[\"input\"], \n",
    "    output_names=[\"output\"], \n",
    "    dynamic_axes={\"input\": {0: \"batch_size\"}, \"output\": {0: \"batch_size\"}}, \n",
    "    opset_version=14  # Compatible ONNX opset version\n",
    ")\n",
    "\n",
    "print(f\"Model exported successfully to {onnx_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1a891361",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cynth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\cynth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1`. You can also use `weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\" to C:\\Users\\cynth/.cache\\torch\\hub\\checkpoints\\fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 160M/160M [03:07<00:00, 891kB/s] \n",
      "C:\\Users\\cynth\\AppData\\Local\\Temp\\ipykernel_15160\\1757652021.py:20: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path, map_location=torch.device(\"cpu\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretrained Florence v2 LoRA quantized weights loaded successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cynth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\functional.py:4511: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  * torch.tensor(scale_factors[i], dtype=torch.float32)\n",
      "c:\\Users\\cynth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\ops\\boxes.py:166: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  boxes_x = torch.min(boxes_x, torch.tensor(width, dtype=boxes.dtype, device=boxes.device))\n",
      "c:\\Users\\cynth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\ops\\boxes.py:168: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  boxes_y = torch.min(boxes_y, torch.tensor(height, dtype=boxes.dtype, device=boxes.device))\n",
      "c:\\Users\\cynth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\__init__.py:2040: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  assert condition, message\n",
      "c:\\Users\\cynth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\detection\\transform.py:308: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(s, dtype=torch.float32, device=boxes.device)\n",
      "c:\\Users\\cynth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\detection\\transform.py:309: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  / torch.tensor(s_orig, dtype=torch.float32, device=boxes.device)\n",
      "c:\\Users\\cynth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\onnx\\symbolic_opset9.py:5385: UserWarning: Exporting aten::index operator of advanced indexing in opset 14 is achieved by combination of multiple ONNX operators, including Reshape, Transpose, Concat, and Gather. If indices include negative values, the exported graph will produce incorrect results.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model exported successfully to dinov2_florence2_od.onnx\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import timm\n",
    "import onnx\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "\n",
    "\n",
    "# Load DINOv2 model\n",
    "# model_name = \"vit_small_patch14_dinov2.lvd142m\"  # Adjust as needed\n",
    "# model = timm.create_model(model_name, pretrained=False)\n",
    "# model.eval()\n",
    "\n",
    "# Load a pretrained DETR model (End-to-End Object Detector)\n",
    "# model = torchvision.models.detection.detr_resnet50(pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "# Load Florence v2 quantized weights\n",
    "checkpoint_path = \"florence2_lora_quantized_pruned_int8.pt\"\n",
    "checkpoint = torch.load(checkpoint_path, map_location=torch.device(\"cpu\"))\n",
    "model.load_state_dict(checkpoint, strict=False)\n",
    "\n",
    "print(\"Pretrained Florence v2 LoRA quantized weights loaded successfully!\")\n",
    "\n",
    "# Dummy input (assuming image size is 518x518 as per DINOv2)\n",
    "dummy_input = torch.randn(1, 3, 518, 518)\n",
    "\n",
    "# Export to ONNX with object detection outputs\n",
    "onnx_path = \"dinov2_florence2_od.onnx\"\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    dummy_input,\n",
    "    onnx_path,\n",
    "    input_names=[\"input\"],\n",
    "    output_names=[\"bboxes\", \"labels\"],  # Include outputs needed for OD\n",
    "    dynamic_axes={\"input\": {0: \"batch_size\"}, \"bboxes\": {0: \"batch_size\"}, \"labels\": {0: \"batch_size\"}},\n",
    "    opset_version=14\n",
    ")\n",
    "\n",
    "print(f\"Model exported successfully to {onnx_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "437debfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Output Shape: torch.Size([1, 1000])\n"
     ]
    }
   ],
   "source": [
    "# Run a forward pass to inspect the output format\n",
    "with torch.no_grad():\n",
    "    sample_output = model(dummy_input)\n",
    "    print(f\"Model Output Shape: {sample_output.shape}\")  # Debug output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249984a4",
   "metadata": {},
   "source": [
    "## This normally saves the model = 1GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e81580a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the model as a .pt file\n",
    "SAVE_PATH = \"florence2_lora.pt\"\n",
    "torch.save(peft_model.state_dict(), SAVE_PATH)\n",
    "print(f\"Model saved to {SAVE_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9caa0101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.2\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "print(numpy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876c0dbb",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "microsoft/florence-v2 is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\cynth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\utils\\_http.py:406\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[1;34m(response, endpoint_name)\u001b[0m\n\u001b[0;32m    405\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 406\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    407\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\cynth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\requests\\models.py:1024\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1023\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[1;32m-> 1024\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[1;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/microsoft/florence-v2/resolve/main/config.json",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\cynth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\utils\\hub.py:403\u001b[0m, in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    401\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[1;32m--> 403\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    416\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\cynth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\cynth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:860\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[1;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[0;32m    859\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 860\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    861\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[0;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    863\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[0;32m    864\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    866\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    867\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[0;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    870\u001b[0m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    871\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    872\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    873\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[0;32m    875\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\cynth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:967\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[1;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[0;32m    966\u001b[0m     \u001b[38;5;66;03m# Otherwise, raise appropriate error\u001b[39;00m\n\u001b[1;32m--> 967\u001b[0m     \u001b[43m_raise_on_head_call_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead_call_error\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    969\u001b[0m \u001b[38;5;66;03m# From now on, etag, commit_hash, url and size are not None.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\cynth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:1482\u001b[0m, in \u001b[0;36m_raise_on_head_call_error\u001b[1;34m(head_call_error, force_download, local_files_only)\u001b[0m\n\u001b[0;32m   1480\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, RepositoryNotFoundError) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(head_call_error, GatedRepoError):\n\u001b[0;32m   1481\u001b[0m     \u001b[38;5;66;03m# Repo not found or gated => let's raise the actual error\u001b[39;00m\n\u001b[1;32m-> 1482\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m head_call_error\n\u001b[0;32m   1483\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1484\u001b[0m     \u001b[38;5;66;03m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\cynth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:1374\u001b[0m, in \u001b[0;36m_get_metadata_or_catch_error\u001b[1;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[0;32m   1373\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1374\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m \u001b[43mget_hf_file_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1375\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\n\u001b[0;32m   1376\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1377\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n",
      "File \u001b[1;32mc:\\Users\\cynth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[1;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\cynth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:1294\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[1;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[0m\n\u001b[0;32m   1293\u001b[0m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[1;32m-> 1294\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHEAD\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1296\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1300\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1301\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1302\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1303\u001b[0m hf_raise_for_status(r)\n",
      "File \u001b[1;32mc:\\Users\\cynth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:278\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[1;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[1;32m--> 278\u001b[0m     response \u001b[38;5;241m=\u001b[39m _request_wrapper(\n\u001b[0;32m    279\u001b[0m         method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m    280\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[0;32m    281\u001b[0m         follow_relative_redirects\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    282\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[0;32m    283\u001b[0m     )\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\cynth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:302\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[1;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[0;32m    301\u001b[0m response \u001b[38;5;241m=\u001b[39m get_session()\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m--> 302\u001b[0m \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\cynth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\utils\\_http.py:454\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[1;34m(response, endpoint_name)\u001b[0m\n\u001b[0;32m    446\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    447\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Client Error.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    448\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    452\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m make sure you are authenticated.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    453\u001b[0m     )\n\u001b[1;32m--> 454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m _format(RepositoryNotFoundError, message, response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m400\u001b[39m:\n",
      "\u001b[1;31mRepositoryNotFoundError\u001b[0m: 401 Client Error. (Request ID: Root=1-67b6b5c1-70062129059cee34703d4115;e1d45973-4407-450e-a0c2-3f4e95243f86)\n\nRepository Not Found for url: https://huggingface.co/microsoft/florence-v2/resolve/main/config.json.\nPlease make sure you specified the correct `repo_id` and `repo_type`.\nIf you are trying to access a private or gated repo, make sure you are authenticated.\nInvalid username or password.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoModel\n\u001b[0;32m      4\u001b[0m model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmicrosoft/florence-v2\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Ensure this is the correct model ID\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m pytorch_model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m dummy_input \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m)  \u001b[38;5;66;03m# Adjust based on the input shape\u001b[39;00m\n\u001b[0;32m      8\u001b[0m torch\u001b[38;5;241m.\u001b[39monnx\u001b[38;5;241m.\u001b[39mexport(pytorch_model, dummy_input, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflorencev2.onnx\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\cynth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:487\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m commit_hash \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    485\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, PretrainedConfig):\n\u001b[0;32m    486\u001b[0m         \u001b[38;5;66;03m# We make a call to the config file first (which may be absent) to get the commit hash as soon as possible\u001b[39;00m\n\u001b[1;32m--> 487\u001b[0m         resolved_config_file \u001b[38;5;241m=\u001b[39m cached_file(\n\u001b[0;32m    488\u001b[0m             pretrained_model_name_or_path,\n\u001b[0;32m    489\u001b[0m             CONFIG_NAME,\n\u001b[0;32m    490\u001b[0m             _raise_exceptions_for_gated_repo\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    491\u001b[0m             _raise_exceptions_for_missing_entries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    492\u001b[0m             _raise_exceptions_for_connection_errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    493\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs,\n\u001b[0;32m    494\u001b[0m         )\n\u001b[0;32m    495\u001b[0m         commit_hash \u001b[38;5;241m=\u001b[39m extract_commit_hash(resolved_config_file, commit_hash)\n\u001b[0;32m    496\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\cynth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\utils\\hub.py:426\u001b[0m, in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[0;32m    421\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[0;32m    422\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are trying to access a gated repo.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mMake sure to have access to it at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    423\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    424\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    425\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RepositoryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 426\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[0;32m    427\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a local folder and is not a valid model identifier \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    428\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlisted on \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/models\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mIf this is a private repository, make sure to pass a token \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    429\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhaving permission to this repo either by logging in with `huggingface-cli login` or by passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    430\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`token=<your_token>`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    431\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RevisionNotFoundError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    433\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[0;32m    434\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrevision\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a valid git identifier (branch name, tag name or commit id) that exists \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    435\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfor this model name. Check the model page at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    436\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for available revisions.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    437\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mOSError\u001b[0m: microsoft/florence-v2 is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo either by logging in with `huggingface-cli login` or by passing `token=<your_token>`"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModel\n",
    "\n",
    "model_name = \"microsoft/Florence-2-base-ft\"  # Ensure this is the correct model ID\n",
    "pytorch_model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "dummy_input = torch.randn(1, 3, 224, 224)  # Adjust based on the input shape\n",
    "torch.onnx.export(pytorch_model, dummy_input, \"florencev2.onnx\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
